{
    "batch_size" : 16,
    "d_model" : 128,
    "dim_forward" : 128,
    "n_heads" : 4,
    "n_layers" : 11,
    "dropout" : 0.104,
    "learning_rate": 0.037,
    "loss_penalty" : 0.27,
    "grad_clip" : 100.0,
    "epochs" : 100,
    "data_augmentation" : false
}